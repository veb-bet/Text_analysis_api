# Text_analysis_api
API для анализа текста, которое позволяет пользователям загружать текст и получать результаты его анализа.

## Возможности

- Подсчёт частоты слов
- Удаление стоп-слов (с учетом языка)
- Вывод 5 самых популярных слов
- Анализ тональности текста (положительный, нейтральный, отрицательный)
- Автоматическое определение языка (поддерживаются многие языки)

---

## Установка

1. Клонируйте репозиторий или сохраните файл `main.py`.
2. Установите зависимости:

```bash
pip install fastapi[all] nltk langdetect
```

Запустите приложение:
```bash
uvicorn main:app --reload
```

## Использование
Откройте в браузере:

```bash
http://localhost:8000/docs
```
Там находится автоматическая Swagger-документация, где можно протестировать API.

Пример запроса (POST /analyze_text/):
```json
{
  "text": "I love natural language processing! It's amazing and powerful."
}
```

Пример ответа:
```json
{
  "language": "en",
  "word_counts": {
    "love": 1,
    "natural": 1,
    "language": 1,
    "processing": 1,
    "amazing": 1,
    "powerful": 1
  },
  "most_common_words": [
    ["love", 1],
    ["natural", 1],
    ["language", 1],
    ["processing", 1],
    ["amazing", 1]
  ],
  "sentiment": {
    "neg": 0.0,
    "neu": 0.417,
    "pos": 0.583,
    "compound": 0.8519
  }
}
```

## Примечания

Анализ тональности работает на английском языке с помощью nltk.SentimentIntensityAnalyzer. Для других языков может быть не точным.
Для корректной работы необходимо загрузить ресурсы NLTK при первом запуске.
